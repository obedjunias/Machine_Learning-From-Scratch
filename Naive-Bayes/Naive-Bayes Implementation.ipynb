{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Bayes’ Theorem provides a way that we can calculate the probability of a piece of data belonging to a given class, given our prior knowledge. Bayes’ Theorem is stated as:\n",
    "\n",
    "    P(class|data) = (P(data|class) * P(class)) / P(data)\n",
    "\n",
    "Where P(class|data) is the probability of class given the provided data.\n",
    "\n",
    "Naive Bayes is a classification algorithm for binary (two-class) and multiclass classification problems. It is called Naive Bayes or idiot Bayes because the calculations of the probabilities for each class are simplified to make their calculations tractable.\n",
    "\n",
    "Rather than attempting to calculate the probabilities of each attribute value, they are assumed to be conditionally independent given the class value.\n",
    "\n",
    "This is a very strong assumption that is most unlikely in real data, i.e. that the attributes do not interact. Nevertheless, the approach performs surprisingly well on data where this assumption does not hold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate By Class\n",
    "\n",
    "We will need to calculate the probability of data by the class they belong to, the so-called base rate.\n",
    "\n",
    "This means that we will first need to separate our training data by class. A relatively straightforward operation.\n",
    "\n",
    "We can create a dictionary object where each key is the class value and then add a list of all the records as the value in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is done so as to cluster the data on the basis of the class it belongs to, so that we can perform any sort of computation diretly on that cluster easily.\n",
    "\n",
    "def seperate_by_class(dataset):\n",
    "    seperated = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        vectors = dataset[i]\n",
    "        cls = vectors[-1]\n",
    "        \n",
    "        if cls not in seperated:\n",
    "            seperated[cls] = []\n",
    "        seperated[cls].append(vectors)\n",
    "    return seperated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test our function\n",
    "\n",
    "# Test separating data by class\n",
    "dataset = [[3.393533211,2.331273381,0],\n",
    "\t[3.110073483,1.781539638,0],\n",
    "\t[1.343808831,3.368360954,0],\n",
    "\t[3.582294042,4.67917911,0],\n",
    "\t[2.280362439,2.866990263,0],\n",
    "\t[7.423436942,4.696522875,1],\n",
    "\t[5.745051997,3.533989803,1],\n",
    "\t[9.172168622,2.511101045,1],\n",
    "\t[7.792783481,3.424088941,1],\n",
    "\t[7.939820817,0.791637231,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.393533</td>\n",
       "      <td>2.331273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.110073</td>\n",
       "      <td>1.781540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.343809</td>\n",
       "      <td>3.368361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.582294</td>\n",
       "      <td>4.679179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.280362</td>\n",
       "      <td>2.866990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.423437</td>\n",
       "      <td>4.696523</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.745052</td>\n",
       "      <td>3.533990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.172169</td>\n",
       "      <td>2.511101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.792783</td>\n",
       "      <td>3.424089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.939821</td>\n",
       "      <td>0.791637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2  y\n",
       "0  3.393533  2.331273  0\n",
       "1  3.110073  1.781540  0\n",
       "2  1.343809  3.368361  0\n",
       "3  3.582294  4.679179  0\n",
       "4  2.280362  2.866990  0\n",
       "5  7.423437  4.696523  1\n",
       "6  5.745052  3.533990  1\n",
       "7  9.172169  2.511101  1\n",
       "8  7.792783  3.424089  1\n",
       "9  7.939821  0.791637  1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(dataset)\n",
    "test_df.columns = ['X1','X2','y']\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[3.393533211, 2.331273381, 0]\n",
      "[3.110073483, 1.781539638, 0]\n",
      "[1.343808831, 3.368360954, 0]\n",
      "[3.582294042, 4.67917911, 0]\n",
      "[2.280362439, 2.866990263, 0]\n",
      "1\n",
      "[7.423436942, 4.696522875, 1]\n",
      "[5.745051997, 3.533989803, 1]\n",
      "[9.172168622, 2.511101045, 1]\n",
      "[7.792783481, 3.424088941, 1]\n",
      "[7.939820817, 0.791637231, 1]\n",
      "{0: [[3.393533211, 2.331273381, 0], [3.110073483, 1.781539638, 0], [1.343808831, 3.368360954, 0], [3.582294042, 4.67917911, 0], [2.280362439, 2.866990263, 0]], 1: [[7.423436942, 4.696522875, 1], [5.745051997, 3.533989803, 1], [9.172168622, 2.511101045, 1], [7.792783481, 3.424088941, 1], [7.939820817, 0.791637231, 1]]}\n"
     ]
    }
   ],
   "source": [
    "separated = seperate_by_class(dataset)\n",
    "for label in separated:\n",
    "\tprint(label)\n",
    "\tfor row in separated[label]:\n",
    "\t\tprint(row)\n",
    "print(separated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Dataset\n",
    "\n",
    "We need two statistics from a given set of data.\n",
    "\n",
    "We’ll see how these statistics are used in the calculation of probabilities in a few steps. The two statistics we require from a given dataset are the mean and the standard deviation (average deviation from the mean).\n",
    "\n",
    "The mean is the average value and can be calculated as:\n",
    "\n",
    "    mean = sum(x)/n * count(x)\n",
    "\n",
    "Where x is the list of values or a column we are looking.\n",
    "\n",
    "The sample standard deviation is calculated as the mean difference from the mean value. This can be calculated as:\n",
    "\n",
    "    standard deviation = sqrt((sum i to N (x_i – mean(x))^2) / N-1)\n",
    "\n",
    "You can see that we square the difference between the mean and a given value, calculate the average squared difference from the mean, then take the square root to return the units back to their original value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(data):\n",
    "    return sum(data)/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(data):\n",
    "    avg = mean(data)\n",
    "    var = sum([(x-avg)**2 for x in data])/float(len(data)-1)\n",
    "    return np.sqrt(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = zip(*dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.393533211, 3.110073483, 1.343808831, 3.582294042, 2.280362439, 7.423436942, 5.745051997, 9.172168622, 7.792783481, 7.939820817)\n",
      "(2.331273381, 1.781539638, 3.368360954, 4.67917911, 2.866990263, 4.696522875, 3.533989803, 2.511101045, 3.424088941, 0.791637231)\n",
      "(0, 0, 0, 0, 0, 1, 1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for each in t:\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3.393533211, 3.110073483, 1.343808831, 3.582294042, 2.280362439, 7.423436942, 5.745051997, 9.172168622, 7.792783481, 7.939820817) - (2.331273381, 1.781539638, 3.368360954, 4.67917911, 2.866990263, 4.696522875, 3.533989803, 2.511101045, 3.424088941, 0.791637231) - (0, 0, 0, 0, 0, 1, 1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "a,b,c = zip(*dataset)\n",
    "print(a,'-',b,'-',c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean, stdev and count for each column in a dataset\n",
    "def summarize_dataset(dataset):\n",
    "    summaries = [(mean(column), std(column), len(column)) for column in zip(*dataset)]\n",
    "    del(summaries[-1]) #deleting the sumaryof the last column (for the classes)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.5, 2.1213203435596424, 2), (3.5, 2.1213203435596424, 2)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_dataset([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5.178333386499999, 2.7665845055177263, 10),\n",
       " (2.9984683241, 1.218556343617447, 10)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize Data By Class\n",
    "\n",
    "We require statistics from our training dataset organized by class.\n",
    "\n",
    "Above, we have developed the separate_by_class() function to separate a dataset into rows by class. And we have developed summarize_dataset() function to calculate summary statistics for each column.\n",
    "\n",
    "We can put all of this together and summarize the columns in the dataset organized by class values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noe again we summarize the data based the cluster created on the basis of the class, so that we can differentiate the summaries obtained from diferent classes.\n",
    "def summarize_by_class(dataset):\n",
    "    summaries = dict()\n",
    "    separated = seperate_by_class(dataset)\n",
    "    for cls,rows in separated.items():\n",
    "        summaries[cls] = summarize_dataset(rows)\n",
    "    return summaries\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(2.7420144012, 0.9265683289298018, 5),\n",
       "  (3.0054686692, 1.1073295894898725, 5)],\n",
       " 1: [(7.6146523718, 1.2344321550313704, 5),\n",
       "  (2.9914679790000003, 1.4541931384601618, 5)]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_by_class(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Probability Density Function\n",
    "\n",
    "Calculating the probability or likelihood of observing a given real-value like X1 is difficult.\n",
    "\n",
    "One way we can do this is to assume that X1 values are drawn from a distribution, such as a bell curve or Gaussian distribution.\n",
    "\n",
    "A Gaussian distribution can be summarized using only two numbers: the mean and the standard deviation. Therefore, with a little math, we can estimate the probability of a given value. This piece of math is called a Gaussian Probability Distribution Function (or Gaussian PDF) and can be calculated as:\n",
    "\n",
    "    f(x) = (1 / sqrt(2 * PI) * sigma) * exp(-((x-mean)^2 / (2 * sigma^2)))\n",
    "\n",
    "Where sigma is the standard deviation for x, mean is the mean for x and PI is the value of pi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi,sqrt,exp\n",
    "def calculate_probability(mean,std,x):\n",
    "    z = (x-mean)/std\n",
    "    prob = (1/sqrt(2*pi*pow(std,2))*(exp((-1/2)*pow(z,2))))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_probability(1.0, 1.0, 1.0)-> 0.3989422804014327\n",
      "calculate_probability(2.0, 1.0, 1.0)-> 0.24197072451914337\n",
      "calculate_probability(0.0, 1.0, 1.0)-> 0.24197072451914337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Running it prints the probability of some input values. You can see that when the value is 1 and the mean and standard deviation is 1 our input is the most likely (top of the bell curve) and has the probability of 0.39.\\n\\nWe can see that when we keep the statistics the same and change the x value to 1 standard deviation either side of the mean value (2 and 0 or the same distance either side of the bell curve) the probabilities of those input values are the same at 0.24.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Gaussian PDF\n",
    "print('calculate_probability(1.0, 1.0, 1.0)->',calculate_probability(1.0, 1.0, 1.0))\n",
    "print('calculate_probability(2.0, 1.0, 1.0)->',calculate_probability(2.0, 1.0, 1.0))\n",
    "print('calculate_probability(0.0, 1.0, 1.0)->',calculate_probability(0.0, 1.0, 1.0))\n",
    "\"\"\"Running it prints the probability of some input values. You can see that when the value is 1 and the mean and standard deviation is 1 our input is the most likely (top of the bell curve) and has the probability of 0.39.\n",
    "\n",
    "We can see that when we keep the statistics the same and change the x value to 1 standard deviation either side of the mean value (2 and 0 or the same distance either side of the bell curve) the probabilities of those input values are the same at 0.24.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Probabilities\n",
    "\n",
    "Now it is time to use the statistics calculated from our training data to calculate probabilities for new data.\n",
    "\n",
    "Probabilities are calculated separately for each class. This means that we first calculate the probability that a new piece of data belongs to the first class, then calculate probabilities that it belongs to the second class, and so on for all the classes.\n",
    "\n",
    "The probability that a piece of data belongs to a class is calculated as follows:\n",
    "\n",
    "    P(class|data) = P(X|class) * P(class)\n",
    "\n",
    "You may note that this is different from the Bayes Theorem described above.\n",
    "\n",
    "The division has been removed to simplify the calculation.\n",
    "\n",
    "This means that the result is no longer strictly a probability of the data belonging to a class. The value is still maximized, meaning that the calculation for the class that results in the largest value is taken as the prediction. This is a common implementation simplification as we are often more interested in the class prediction rather than the probability.\n",
    "\n",
    "The input variables are treated separately, giving the technique it’s name “naive“. For the above example where we have 2 input variables, the calculation of the probability that a row belongs to the first class 0 can be calculated as:\n",
    "\n",
    "    P(class=0|X1,X2) = P(X1|class=0) * P(X2|class=0) * P(class=0)\n",
    "\n",
    "Now you can see why we need to separate the data by class value. The Gaussian Probability Density function in the previous step is how we calculate the probability of a real value like X1 and the statistics we prepared are used in this calculation.\n",
    "\n",
    "Below is a function named calculate_class_probabilities() that ties all of this together.\n",
    "\n",
    "It takes a set of prepared summaries and a new row as input arguments.\n",
    "\n",
    "First the total number of training records is calculated from the counts stored in the summary statistics. This is used in the calculation of the probability of a given class or P(class) as the ratio of rows with a given class of all rows in the training data.\n",
    "\n",
    "Next, probabilities are calculated for each input value in the row using the Gaussian probability density function and the statistics for that column and of that class. Probabilities are multiplied together as they accumulated.\n",
    "\n",
    "This process is repeated for each class in the dataset.\n",
    "\n",
    "Finally a dictionary of probabilities is returned with one entry for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  calculate_class_probabilities(summaries,row):\n",
    "    total_rows = sum([summaries[cls][0][2] for cls in summaries])# here we just consider the first aub array (column) since very column have the same number of entries for a given class.\n",
    "    probabilities = dict()\n",
    "    for cls,cls_summaries in summaries.items():\n",
    "        probabilities[cls] = summaries[cls][0][2]/float(total_rows)\n",
    "        for i in range(len(cls_summaries)): # for each column pertaining to a class\n",
    "            mean,std,count = cls_summaries[i]\n",
    "            probabilities[cls] *= calculate_probability(mean,std,row[i])\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries = summarize_by_class(dataset)\n",
    "sum([summaries[cls][0][2] for cls in summaries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.05032427673372073, 1: 0.00011557718379945776}\n"
     ]
    }
   ],
   "source": [
    "probabilities = calculate_class_probabilities(summaries,dataset[0])\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Flower Species Case Study\n",
    "\n",
    "This section applies the Naive Bayes algorithm to the Iris flowers dataset.\n",
    "\n",
    "The first step is to load the dataset and convert the loaded data to numbers that we can use with the mean and standard deviation calculations. For this we will use the helper function load_csv() to load the file, str_column_to_float() to convert string numbers to floats and str_column_to_int() to convert the class column to integer values.\n",
    "\n",
    "We will evaluate the algorithm using k-fold cross-validation with 5 folds. This means that 150/5=30 records will be in each fold. We will use the helper functions evaluate_algorithm() to evaluate the algorithm with cross-validation and accuracy_metric() to calculate the accuracy of predictions.\n",
    "\n",
    "A new function named predict() was developed to manage the calculation of the probabilities of a new row belonging to each class and selecting the class with the largest probability value.\n",
    "\n",
    "Another new function named naive_bayes() was developed to manage the application of the Naive Bayes algorithm, first learning the statistics from a training dataset and using them to make predictions for a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
